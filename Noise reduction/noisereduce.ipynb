{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ksaqu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.layers import Conv3D, MaxPooling3D\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, ZeroPadding3D, TimeDistributed, LSTM, GRU, Reshape\n",
    "#from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from prettytable import PrettyTable\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Reduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise reduction completed for 0.mp4\n",
      "Noise reduction completed for 1.mp4\n",
      "Noise reduction completed for 10.mp4\n",
      "Noise reduction completed for 2.mp4\n",
      "Noise reduction completed for 3.mp4\n",
      "Noise reduction completed for 4.mp4\n",
      "Noise reduction completed for 5.mp4\n",
      "Noise reduction completed for 6.mp4\n",
      "Noise reduction completed for 7.mp4\n",
      "Noise reduction completed for 8.mp4\n",
      "Noise reduction completed for 9.mp4\n",
      "Noise reduction completed for box.mp4\n",
      "Noise reduction completed for fun.mp4\n",
      "Noise reduction completed for good.mp4\n",
      "Noise reduction completed for grow.mp4\n",
      "Noise reduction completed for hero.mp4\n",
      "Noise reduction completed for trust.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def reduce_noise(input_folder, output_folder):\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Loop through each file in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".mp4\"):  # Assuming all files are videos\n",
    "            video_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "            # Open the video file\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "            # Create VideoWriter object\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "            # Process each frame\n",
    "            for _ in range(frame_count):\n",
    "                ret, frame = cap.read()\n",
    "                if ret:\n",
    "                    # Apply Gaussian blur for noise reduction\n",
    "                    blurred_frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "                    out.write(blurred_frame)\n",
    "\n",
    "            # Release resources\n",
    "            cap.release()\n",
    "            out.release()\n",
    "\n",
    "            print(f\"Noise reduction completed for {filename}\")\n",
    "\n",
    "# Example usage:\n",
    "input_folder = \"D:\\\\New Dataset Lip Movement Projec\\\\FINAL YEAR PROJECT\\\\Noise reduction\\\\Dataset2.0\"\n",
    "output_folder = \"D:\\\\New Dataset Lip Movement Projec\\\\FINAL YEAR PROJECT\\\\Noise reduction\\\\output\"\n",
    "reduce_noise(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 246 images belonging to 17 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52 images belonging to 17 classes.\n",
      "WARNING:tensorflow:From c:\\Users\\ksaqu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ksaqu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ksaqu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 94, 70, 64)        1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 47, 35, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 45, 33, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 22, 16, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 20, 14, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 10, 7, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 5, 128)         147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 4, 2, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 17)                8721      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 904337 (3.45 MB)\n",
      "Trainable params: 904337 (3.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Define constants\n",
    "IMAGE_SIZE = (96, 72)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "NUM_CLASSES = 17\n",
    "TRAIN_DATA_DIR = \"D:\\\\New Dataset Lip Movement Projec\\\\FINAL YEAR PROJECT\\\\output_denoised_image_folder\"\n",
    "\n",
    "# Define data generator\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Load and preprocess the data\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    TRAIN_DATA_DIR,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    TRAIN_DATA_DIR,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(64, (3, 3), activation='relu', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 3s 150ms/step - loss: 2.8505 - accuracy: 0.0478 - val_loss: 2.8309 - val_accuracy: 0.0625\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 2s 105ms/step - loss: 2.8375 - accuracy: 0.0652 - val_loss: 2.8264 - val_accuracy: 0.0833\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 2s 114ms/step - loss: 2.8305 - accuracy: 0.0652 - val_loss: 2.8177 - val_accuracy: 0.0625\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 2.7735 - accuracy: 0.1087 - val_loss: 2.5745 - val_accuracy: 0.2083\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 2.4676 - accuracy: 0.1792 - val_loss: 2.2378 - val_accuracy: 0.2292\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 2.2445 - accuracy: 0.2130 - val_loss: 2.1215 - val_accuracy: 0.2292\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 2.0027 - accuracy: 0.2783 - val_loss: 2.0716 - val_accuracy: 0.2917\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 1.8241 - accuracy: 0.4174 - val_loss: 1.7861 - val_accuracy: 0.2500\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.6573 - accuracy: 0.4739 - val_loss: 1.7399 - val_accuracy: 0.4583\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.4594 - accuracy: 0.5348 - val_loss: 1.5952 - val_accuracy: 0.5208\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 2s 123ms/step - loss: 1.3190 - accuracy: 0.5696 - val_loss: 1.6217 - val_accuracy: 0.4167\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 2s 124ms/step - loss: 1.0773 - accuracy: 0.6458 - val_loss: 1.3510 - val_accuracy: 0.5833\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 2s 125ms/step - loss: 0.8805 - accuracy: 0.7087 - val_loss: 1.2669 - val_accuracy: 0.5625\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 2s 124ms/step - loss: 0.8700 - accuracy: 0.6739 - val_loss: 1.3832 - val_accuracy: 0.5833\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.7760 - accuracy: 0.7917 - val_loss: 1.2206 - val_accuracy: 0.6250\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 0.5870 - accuracy: 0.8348 - val_loss: 1.1280 - val_accuracy: 0.5833\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 0.4582 - accuracy: 0.8739 - val_loss: 0.6809 - val_accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 0.3119 - accuracy: 0.9304 - val_loss: 0.7894 - val_accuracy: 0.7083\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.5085 - accuracy: 0.8565 - val_loss: 0.7621 - val_accuracy: 0.7083\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.2614 - accuracy: 0.9261 - val_loss: 0.5092 - val_accuracy: 0.7917\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 0.2265 - accuracy: 0.9417 - val_loss: 0.3049 - val_accuracy: 0.8542\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 2s 114ms/step - loss: 0.1396 - accuracy: 0.9783 - val_loss: 0.2583 - val_accuracy: 0.9167\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.1149 - accuracy: 0.9652 - val_loss: 0.2413 - val_accuracy: 0.9375\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.1088 - accuracy: 0.9696 - val_loss: 0.1408 - val_accuracy: 0.9583\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.1716 - accuracy: 0.9565 - val_loss: 0.4266 - val_accuracy: 0.8125\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 2s 137ms/step - loss: 0.3506 - accuracy: 0.9174 - val_loss: 0.2686 - val_accuracy: 0.8958\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.1757 - accuracy: 0.9609 - val_loss: 0.5231 - val_accuracy: 0.8125\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.1492 - accuracy: 0.9565 - val_loss: 0.2292 - val_accuracy: 0.9167\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 0.1066 - accuracy: 0.9696 - val_loss: 0.4076 - val_accuracy: 0.8750\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 2s 104ms/step - loss: 0.1943 - accuracy: 0.9565 - val_loss: 0.6714 - val_accuracy: 0.8958\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.2435 - accuracy: 0.9174 - val_loss: 0.1917 - val_accuracy: 0.9583\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 2s 123ms/step - loss: 0.1430 - accuracy: 0.9609 - val_loss: 0.0780 - val_accuracy: 0.9792\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 2s 138ms/step - loss: 0.1050 - accuracy: 0.9565 - val_loss: 0.4816 - val_accuracy: 0.8750\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.1921 - accuracy: 0.9522 - val_loss: 0.4988 - val_accuracy: 0.8125\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.1270 - accuracy: 0.9696 - val_loss: 0.1714 - val_accuracy: 0.9167\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 2s 125ms/step - loss: 0.0590 - accuracy: 0.9826 - val_loss: 0.2250 - val_accuracy: 0.9167\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 2s 125ms/step - loss: 0.0532 - accuracy: 0.9783 - val_loss: 0.0394 - val_accuracy: 0.9792\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 2s 130ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 2s 126ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 0.0078 - accuracy: 0.9957 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 2s 123ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 8.2351e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 2s 106ms/step - loss: 8.5510e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 8.9897e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 2s 114ms/step - loss: 8.1434e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 2s 106ms/step - loss: 7.3289e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 2s 105ms/step - loss: 6.2850e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 2s 106ms/step - loss: 7.0178e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 2s 105ms/step - loss: 5.4577e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 2s 106ms/step - loss: 5.9503e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 5.6028e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 5.3521e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 4.8740e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 2s 105ms/step - loss: 4.8453e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 4.5931e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 2s 106ms/step - loss: 4.8167e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 3.9636e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 2s 106ms/step - loss: 3.9530e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 3.8844e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 2s 106ms/step - loss: 3.2342e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 3.5581e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 3.5123e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 3.3555e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 2.9424e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 2s 106ms/step - loss: 3.0923e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 2.8170e-04 - accuracy: 1.0000 - val_loss: 8.9533e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 2.6734e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 2s 106ms/step - loss: 2.7561e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 2.7275e-04 - accuracy: 1.0000 - val_loss: 9.6096e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 2s 113ms/step - loss: 2.6497e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 2.3284e-04 - accuracy: 1.0000 - val_loss: 9.1686e-04 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 2.3827e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 2s 106ms/step - loss: 2.2987e-04 - accuracy: 1.0000 - val_loss: 9.5851e-04 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 2s 106ms/step - loss: 2.2404e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 2s 105ms/step - loss: 2.2524e-04 - accuracy: 1.0000 - val_loss: 7.5633e-04 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 2.1027e-04 - accuracy: 1.0000 - val_loss: 7.6255e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 2s 104ms/step - loss: 1.8760e-04 - accuracy: 1.0000 - val_loss: 9.3525e-04 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 2s 105ms/step - loss: 2.0800e-04 - accuracy: 1.0000 - val_loss: 8.7380e-04 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 1.9533e-04 - accuracy: 1.0000 - val_loss: 6.8355e-04 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 2s 105ms/step - loss: 1.9015e-04 - accuracy: 1.0000 - val_loss: 7.3309e-04 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 2s 106ms/step - loss: 1.6663e-04 - accuracy: 1.0000 - val_loss: 6.5352e-04 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 1.7402e-04 - accuracy: 1.0000 - val_loss: 7.4681e-04 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 1.6141e-04 - accuracy: 1.0000 - val_loss: 7.5608e-04 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 2s 105ms/step - loss: 1.5809e-04 - accuracy: 1.0000 - val_loss: 7.3768e-04 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 1.6308e-04 - accuracy: 1.0000 - val_loss: 6.8187e-04 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 2s 105ms/step - loss: 1.6399e-04 - accuracy: 1.0000 - val_loss: 7.0491e-04 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 1.2409e-04 - accuracy: 1.0000 - val_loss: 5.9601e-04 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 1.4927e-04 - accuracy: 1.0000 - val_loss: 5.1731e-04 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 1.4832e-04 - accuracy: 1.0000 - val_loss: 6.8521e-04 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 2s 106ms/step - loss: 1.4395e-04 - accuracy: 1.0000 - val_loss: 5.6097e-04 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 1.5367e-04 - accuracy: 1.0000 - val_loss: 6.4596e-04 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 1.4007e-04 - accuracy: 1.0000 - val_loss: 6.2379e-04 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 1.3385e-04 - accuracy: 1.0000 - val_loss: 6.3077e-04 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 1.3181e-04 - accuracy: 1.0000 - val_loss: 4.1736e-04 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 1.2727e-04 - accuracy: 1.0000 - val_loss: 5.2731e-04 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 1.3013e-04 - accuracy: 1.0000 - val_loss: 6.1441e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ksaqu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 30ms/step - loss: 1.1815e-04 - accuracy: 1.0000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 5.7941e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 100.0\n",
      "Validation Accuracy: 100.0\n",
      "Trainig time: 171.78111267089844\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time=time.time()\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute the computational time\n",
    "comp_time = end_time - start_time\n",
    "\n",
    "model.save('cnnown1.h5')\n",
    "# Evaluate the model\n",
    "train_loss, train_acc = model.evaluate(train_generator)\n",
    "val_loss, val_acc = model.evaluate(validation_generator)\n",
    "\n",
    "print(f'Training Accuracy: {train_acc * 100}')\n",
    "print(f'Validation Accuracy: {val_acc * 100}')\n",
    "print(f'Trainig time: {comp_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 298 images belonging to 17 classes.\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# # Create an ImageDataGenerator object\n",
    "# datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# # Create a generator\n",
    "# generator = datagen.flow_from_directory(\n",
    "#     'D:\\\\New Dataset Lip Movement Projec\\\\FINAL YEAR PROJECT\\\\output_denoised_image_folder',\n",
    "#     target_size=(150, 150),\n",
    "#     batch_size=16,\n",
    "#     class_mode='binary'\n",
    "# )\n",
    "\n",
    "# print(generator.batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Normal Frames into GLCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m frame_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, frame)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Read the image\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Apply GLCM noise reduction\u001b[39;00m\n\u001b[0;32m     41\u001b[0m reduced_noise_image \u001b[38;5;241m=\u001b[39m glcm_noise_reduction(image)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "\n",
    "def glcm_noise_reduction(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Compute the GLCM of the grayscale image\n",
    "    glcm = graycomatrix(gray, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4])\n",
    "\n",
    "    # Compute the mean of the GLCM\n",
    "    mean_glcm = np.mean(glcm)\n",
    "\n",
    "    # Subtract the mean from the original image to reduce noise\n",
    "    reduced_noise_image = gray - mean_glcm\n",
    "\n",
    "    return reduced_noise_image\n",
    "\n",
    "# Specify the directory containing the folders with frames\n",
    "root_dir = 'D:\\\\New Dataset Lip Movement Projec\\\\FINAL YEAR PROJECT\\\\Frames'\n",
    "\n",
    "# Create a new folder to save all the noise-reduced images\n",
    "new_root_dir = 'D:\\\\New Dataset Lip Movement Projec\\\\FINAL YEAR PROJECT\\\\output_denoised_image_folder'\n",
    "\n",
    "# Loop over each folder (video)\n",
    "for folder in os.listdir(root_dir):\n",
    "    folder_path = os.path.join(root_dir, folder)\n",
    "    new_folder_path = os.path.join(new_root_dir, folder)\n",
    "    os.makedirs(new_folder_path, exist_ok=True)\n",
    "\n",
    "    # Loop over each image (frame) in the folder\n",
    "    for frame in os.listdir(folder_path):\n",
    "        frame_path = os.path.join(folder_path, frame)\n",
    "\n",
    "        # Read the image\n",
    "        image = cv2.imread(frame_path)\n",
    "\n",
    "        # Apply GLCM noise reduction\n",
    "        reduced_noise_image = glcm_noise_reduction(image)\n",
    "\n",
    "        # Save the noise-reduced image in the new folder\n",
    "        cv2.imwrite(os.path.join(new_folder_path, frame), reduced_noise_image)\n",
    "\n",
    "print('Noise reduction completed.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
